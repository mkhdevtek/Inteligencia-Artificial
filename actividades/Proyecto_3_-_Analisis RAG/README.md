---
tags:
  - actividad
  - inteligencia-artificial
  - unidad-4
---
Para este proyecto se utilizaron modelos de Ollama, específicamente `llama3.2` y `deepseek-r1:1.5b`. Y utilizando Anything LLM como chat intermediario para realizar las preguntas sobre el tema.

En un proyecto de Anything LLM se carga el archivo csv del dataset de 5000 tweets sintéticos como **RAG** y se realizo la siguiente pregunta:

![](./attachments/Pasted%20image%2020251207174122.png)

La respuesta no fue 100% precisa, sin embargo, entendió el contexto proporcionado y como realizar una lectura.

Después de verificar que el modelo entienda el contexto del documento embebido se realizó la pregunta principal *¿Está la Generación Z viviendo una crisis de sentido debido a la hiperconectividad, el exceso de información y la falta de proyectos compartidos?*

![](attachments/Pasted%20image%2020251207174304.png)

Si bien el modelo realizó un razonamiento sobre el RAG proporcionado, no respondió completamente con la información proporcionada, sino con información extra o "alucinaciones" que el modelo tiene.

Una vez que considere que la respuesta satisface comencé a realizar las demás preguntas. Pues considere que las respuestas estaban relacionadas al dataset proporcionado.

![](attachments/Pasted%20image%2020251208153134.png)

![](attachments/Pasted%20image%2020251208153513.png)

![](attachments/Pasted%20image%2020251208154312.png)


![](attachments/Pasted%20image%2020251208154647.png)

![](attachments/penultima.jpg)

![](attachments/Pasted%20image%2020251208160539.png)


La mayoría de las respuestas se consideraron válidas por lo que se consideró terminado el proyecto

